{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "341ee3d5",
   "metadata": {},
   "source": [
    "# Gas Turbine mesurment data processing  \n",
    "##### 1. Getting the data resady to be preprocessed \n",
    "##### 2.  Getting infos for csv data files\n",
    "##### 3. Converting object data to usefull data-types \n",
    "##### 4. Filtering the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aa0a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing modules \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248aaaed",
   "metadata": {},
   "source": [
    "## A.  Getting the data resady to be preprocessed \n",
    "1. Explore the data  manually \n",
    "2. get the list of the datasets names \n",
    "3. Reanme each dataset by its propor name \n",
    "4. convert the txt  data to cvs format \n",
    "5. Rename data column lables "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f5a025",
   "metadata": {},
   "source": [
    "### 1. Get the list of the datasets names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6935ebe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T1_A26BJ1B.txt',\n",
       " 'T1_A26BJ2A.txt',\n",
       " 'T1_A26BJ2B.txt',\n",
       " 'T1_A26BTAA.txt',\n",
       " 'T1_A26BTAB.txt',\n",
       " 'T1_A26BTI.txt',\n",
       " 'T1_A26CBJ1.txt',\n",
       " 'T1_A26CBJ2.txt',\n",
       " 'T1_BB1.txt',\n",
       " 'T1_BB2.txt',\n",
       " 'T1_BBH1.txt',\n",
       " 'T1_BBL1.txt',\n",
       " 'T1_CPD.txt',\n",
       " 'T1_CPR.txt',\n",
       " 'T1_CTD.txt',\n",
       " 'T1_CTIM.txt',\n",
       " 'T1_FD_INTENS_3.txt',\n",
       " 'T1_FD_INTENS_4.txt',\n",
       " 'T1_FD_INTENS_5.txt',\n",
       " 'T1_FD_INTENS_6.txt',\n",
       " 'T1_FD_INTENS_7.txt',\n",
       " 'T1_FD_INTENS_8.txt',\n",
       " 'T1_L28FDA.txt',\n",
       " 'T1_L28FDB.txt',\n",
       " 'T1_TNH.txt',\n",
       " 'T1_TNH1.txt',\n",
       " 'T1_TNH2.txt',\n",
       " 'T1_TNHAR.txt',\n",
       " 'T1_TNL.txt',\n",
       " 'T1_TNLA.txt',\n",
       " 'T1_TTWS1AO.txt',\n",
       " 'T1_TTWS1FI.txt',\n",
       " 'T1_TTXM.txt',\n",
       " 'T3_PTVIB_A.txt',\n",
       " 'T3_PTVIB_B.txt',\n",
       " 'Time,Value,Value Attributes.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## define data neccessary path  \n",
    "\n",
    "data_path =  \"../../Data- INST-TC2\"\n",
    "processed_data1 = \"../../Data- INST-TC2/processed_data\"\n",
    "processed_data2 = \"../../Data- INST-TC2/processed_data2\"\n",
    "\n",
    "# getting the list of files to be processed  \n",
    "file_list1 = os.listdir(data_path) \n",
    "txt_files = [f for f in file_list1 if f.lower().endswith(\".txt\")]\n",
    "txt_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8be304e",
   "metadata": {},
   "source": [
    "### 2. Rename each dataset by its propor name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c50251ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.  Rename the files\n",
    "def rename_files(file_list):\n",
    "    \"\"\"\n",
    "    this function renames all the txt file with their proper name\n",
    "    :param path: the path of the txt data files\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    file_names = file_list \n",
    "\n",
    "    for txt_file in file_names:\n",
    "        with open(data_path + '/' + txt_file, 'r') as f:\n",
    "            lines = f.readline().replace('\\n', '')\n",
    "            #   print(lines)\n",
    "            new_filename = lines.split('\\\\')[-1].replace('.', '_')\n",
    "            print(new_filename)\n",
    "        os.rename(data_path + '/' + txt_file, data_path + '/' + new_filename + '.txt') \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f64f84df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rename_files(txt_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02875e20",
   "metadata": {},
   "source": [
    "### 3. Convert file to csv files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "287fd4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert txt file to csv files \n",
    "def convert_to_csv(path):\n",
    "\n",
    "    # Get a list of all files and directories in the specified path\n",
    "    file_list = os.listdir(path)\n",
    "    # Filter only the text files (ending with \".txt\")\n",
    "    file_names = [f for f in file_list if f.lower().endswith(\".txt\")]\n",
    "    for file_name in file_names:\n",
    "        with open(path + '/' + file_name, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        with open(path + '/' + file_name, 'w') as f:\n",
    "            head = lines[3].replace('\\t', ',')\n",
    "            f.write(head)\n",
    "            for line in lines[4:]:\n",
    "                m_line = line.replace('\\t', ',').replace(' ', ',')\n",
    "                f.write(m_line)\n",
    "        with open(data_path + '/' + file_name, 'r') as f:\n",
    "            m_lines = f.readlines()\n",
    "        #\n",
    "        with open(path + '/' + file_name[:-4] + '.csv', 'w') as csvfile:\n",
    "            csvfile.writelines(m_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "924dbfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert_to_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e35a655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Perform initial preprocessing (name columns ) \n",
    "# save processed datasets to processed_data folder \n",
    "\n",
    "def preprocess_data(path):\n",
    "    proc_path = path + '/processed_data'\n",
    "    file_inpath = os.listdir(path)\n",
    "    csv_files = [f for f in file_inpath if f.lower().endswith(\".csv\")]\n",
    "    new_column_names = [\"Date\", \"Time\", \"Value\"]\n",
    "    for csv_file in csv_files:\n",
    "        new_column_names[-1] = csv_file[:-4]\n",
    "        data = pd.read_csv(path + \"/\" + csv_file, on_bad_lines='skip')\n",
    "        data = data.iloc[::-1]\n",
    "        data = data.set_axis(new_column_names, axis=1)\n",
    "        data.to_csv(processed_data1 + '/' + csv_file, index=False, header=True)\n",
    "        #data = data = pd.read_csv(path + \"/\" + csv_file, on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "865a51f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess_data(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87f5afe",
   "metadata": {},
   "source": [
    "## B. Process data type \n",
    "1. get infos about the data sized and shapes\n",
    "2. convert object data to relevant data types \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7face8d",
   "metadata": {},
   "source": [
    "### 1. Get infos about the data sized and shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5412f5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1_A26BJ1A shape=  (52607, 3)\n",
      "T1_A26BJ1B shape=  (52835, 3)\n",
      "T1_A26BJ2A shape=  (57648, 3)\n",
      "T1_A26BJ2B shape=  (52475, 3)\n",
      "T1_A26BTAA shape=  (66194, 3)\n",
      "T1_A26BTAB shape=  (66082, 3)\n",
      "T1_A26BTI shape=  (49730, 3)\n",
      "T1_A26CBJ1 shape=  (58337, 3)\n",
      "T1_A26CBJ2 shape=  (56983, 3)\n",
      "T1_BB1 shape=  (1396, 3)\n",
      "T1_BB2 shape=  (10729, 3)\n",
      "T1_BBH1 shape=  (1842, 3)\n",
      "T1_BBL1 shape=  (1034, 3)\n",
      "T1_CPD shape=  (638, 3)\n",
      "T1_CPR shape=  (463, 3)\n",
      "T1_CTD shape=  (47421, 3)\n",
      "T1_CTIM shape=  (461, 3)\n",
      "T1_FD_INTENS_3 shape=  (137, 3)\n",
      "T1_FD_INTENS_4 shape=  (137, 3)\n",
      "T1_FD_INTENS_5 shape=  (137, 3)\n",
      "T1_FD_INTENS_6 shape=  (137, 3)\n",
      "T1_FD_INTENS_7 shape=  (137, 3)\n",
      "T1_FD_INTENS_8 shape=  (137, 3)\n",
      "T1_L28FDA shape=  (133, 3)\n",
      "T1_L28FDB shape=  (133, 3)\n",
      "T1_TNH shape=  (624, 3)\n",
      "T1_TNH1 shape=  (1796, 3)\n",
      "T1_TNH2 shape=  (1804, 3)\n",
      "T1_TNHAR shape=  (136, 3)\n",
      "T1_TNL shape=  (406, 3)\n",
      "T1_TNLA shape=  (225, 3)\n",
      "T1_TTWS1AO shape=  (136, 3)\n",
      "T1_TTWS1FI shape=  (16730, 3)\n",
      "T1_TTXM shape=  (341950, 3)\n",
      "T3_PTVIB_A shape=  (1324, 3)\n",
      "T3_PTVIB_B shape=  (1332, 3)\n"
     ]
    }
   ],
   "source": [
    "file_list2 = os.listdir(processed_data1) \n",
    "csv_files = [f for f in file_list2 if f.lower().endswith(\".csv\")]\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(processed_data1 +\"/\"+csv_file, on_bad_lines='skip', low_memory=False) \n",
    "    print(csv_file[:-4], \"shape= \",df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb3914e",
   "metadata": {},
   "source": [
    "### 2. Convert object data to relevant data types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2f86604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to process uknown time \n",
    "def remove_false_time(dataframe):\n",
    "    '''\n",
    "    This function removes the row that contains unknown time that can't be converted to timedelta \n",
    "    \n",
    "    ARGUMENT: \n",
    "        dataframe: pandas dataframe \n",
    "    OUTPUT: \n",
    "        tuple  (dataframe, [index, false time]) \n",
    "    \n",
    "    '''\n",
    "    false_time = [] \n",
    "    print(\"Removing false time ...\")\n",
    "    for i in range(df.shape[0]):\n",
    "        #print(i)\n",
    "        try: \n",
    "            pd.to_timedelta(df['Time'][i])\n",
    "           # print(\"done\")\n",
    "        except: \n",
    "            false_time.append((i,df['Time'][i]))\n",
    "            df.drop(i, inplace=True)\n",
    "            print(\"False time solved\")\n",
    "            continue  \n",
    "    return (df, false_time)\n",
    "    \n",
    "#pd.to_timedelta(df['Time'][1])\n",
    "#df['Time'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "099ef267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1 ... \n",
      "Removing false time ...\n",
      "Processing file 2 ... \n",
      "Removing false time ...\n",
      "Processing file 3 ... \n",
      "Removing false time ...\n",
      "Processing file 4 ... \n",
      "Removing false time ...\n",
      "Processing file 5 ... \n",
      "Removing false time ...\n",
      "Processing file 6 ... \n",
      "Removing false time ...\n",
      "Processing file 7 ... \n",
      "Removing false time ...\n",
      "False time solved\n",
      "Processing file 8 ... \n",
      "Removing false time ...\n",
      "Processing file 9 ... \n",
      "Removing false time ...\n",
      "Processing file 10 ... \n",
      "Removing false time ...\n",
      "Processing file 11 ... \n",
      "Removing false time ...\n",
      "Processing file 12 ... \n",
      "Removing false time ...\n",
      "Processing file 13 ... \n",
      "Removing false time ...\n",
      "Processing file 14 ... \n",
      "Removing false time ...\n",
      "Processing file 15 ... \n",
      "Removing false time ...\n",
      "Processing file 16 ... \n",
      "Removing false time ...\n",
      "Processing file 17 ... \n",
      "Removing false time ...\n",
      "Processing file 18 ... \n",
      "Removing false time ...\n",
      "Processing file 19 ... \n",
      "Removing false time ...\n",
      "Processing file 20 ... \n",
      "Removing false time ...\n",
      "Processing file 21 ... \n",
      "Removing false time ...\n",
      "Processing file 22 ... \n",
      "Removing false time ...\n",
      "Processing file 23 ... \n",
      "Removing false time ...\n",
      "Processing file 24 ... \n",
      "Removing false time ...\n",
      "Processing file 25 ... \n",
      "Removing false time ...\n",
      "Processing file 26 ... \n",
      "Removing false time ...\n",
      "Processing file 27 ... \n",
      "Removing false time ...\n",
      "Processing file 28 ... \n",
      "Removing false time ...\n",
      "Processing file 29 ... \n",
      "Removing false time ...\n",
      "Processing file 30 ... \n",
      "Removing false time ...\n",
      "Processing file 31 ... \n",
      "Removing false time ...\n",
      "Processing file 32 ... \n",
      "Removing false time ...\n",
      "Processing file 33 ... \n",
      "Removing false time ...\n",
      "Processing file 34 ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mazou\\AppData\\Local\\Temp\\ipykernel_7464\\1944462203.py:7: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(processed_data1+ \"/\"+csv_file, on_bad_lines='skip')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing false time ...\n",
      "Processing file 35 ... \n",
      "Removing false time ...\n",
      "Processing file 36 ... \n",
      "Removing false time ...\n"
     ]
    }
   ],
   "source": [
    "# empty dectionary to store dataframes \n",
    "dataframes =  {} ; \n",
    "#function to convert the column data types to pandas datatypes \n",
    "#def convert_topd_datatypes(file_list):\n",
    "for csv_file in csv_files: \n",
    "    print(f\"Processing file {csv_files.index(csv_file) + 1} ... \")\n",
    "    df = pd.read_csv(processed_data1+ \"/\"+csv_file, on_bad_lines='skip') \n",
    "    (df,_) = remove_false_time(df)\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%d-%b-%Y',errors='coerce')\n",
    "        ## process TIME : \n",
    "    df['Time']  = pd.to_timedelta(df['Time'])\n",
    "    df[csv_file[:-4]] = pd.to_numeric(df[csv_file[:-4]], errors='coerce')\n",
    "    #df.to_csv(data_path_2 + '/' + file, index=False, header=True)\n",
    "    dataframes[csv_file[:-4]] = df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0d6e85",
   "metadata": {},
   "source": [
    "## C. Filtering the data\n",
    "1. Extracting information about the dates and times of the data\n",
    "1. 1. Extart how many samples per each day for each data\n",
    "3. get the top most data according to the number of existing days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1bae90",
   "metadata": {},
   "source": [
    "### Extracting information about the dates and times of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d8cfee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = dataframes[csv_files[4][:-4]]\n",
    "df4['Date'][df4.shape[0]-1]\n",
    "df4.shape[0]\n",
    "len(set(df4['Date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43eb77a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing T1_A26BJ1A ...\n",
      "Processing T1_A26BJ1B ...\n",
      "Processing T1_A26BJ2A ...\n",
      "Processing T1_A26BJ2B ...\n",
      "Processing T1_A26BTAA ...\n",
      "Processing T1_A26BTAB ...\n",
      "Processing T1_A26BTI ...\n",
      "Processing T1_A26CBJ1 ...\n",
      "Processing T1_A26CBJ2 ...\n",
      "Processing T1_BB1 ...\n",
      "Processing T1_BB2 ...\n",
      "Processing T1_BBH1 ...\n",
      "Processing T1_BBL1 ...\n",
      "Processing T1_CPD ...\n",
      "Processing T1_CPR ...\n",
      "Processing T1_CTD ...\n",
      "Processing T1_CTIM ...\n",
      "Processing T1_FD_INTENS_3 ...\n",
      "Processing T1_FD_INTENS_4 ...\n",
      "Processing T1_FD_INTENS_5 ...\n",
      "Processing T1_FD_INTENS_6 ...\n",
      "Processing T1_FD_INTENS_7 ...\n",
      "Processing T1_FD_INTENS_8 ...\n",
      "Processing T1_L28FDA ...\n",
      "Processing T1_L28FDB ...\n",
      "Processing T1_TNH ...\n",
      "Processing T1_TNH1 ...\n",
      "Processing T1_TNH2 ...\n",
      "Processing T1_TNHAR ...\n",
      "Processing T1_TNL ...\n",
      "Processing T1_TNLA ...\n",
      "Processing T1_TTWS1AO ...\n",
      "Processing T1_TTWS1FI ...\n",
      "Processing T1_TTXM ...\n",
      "Processing T3_PTVIB_A ...\n",
      "Processing T3_PTVIB_B ...\n"
     ]
    }
   ],
   "source": [
    "## creating a dicyionary to store the following information about the data frames: \n",
    "# first day, last day number of days, and list of all days (a set)\n",
    "dataframes_info = {} \n",
    "for df_key, df in dataframes.items(): \n",
    "    print(\"Processing\", df_key, \"...\")\n",
    "    #print(\" -> First Day\")\n",
    "    first_day = df['Date'][df['Date'].index.start]; \n",
    "    #print(\" -> Last Day\")\n",
    "    last_day = df['Date'][df['Date'].index.stop -1]\n",
    "    #print(\" -> all Day\")\n",
    "    all_days = set(df['Date'])\n",
    "    #print(\" -> num Day\")\n",
    "    num_days = len(set(df['Date'])) \n",
    "    #print(\"Saving Data ... \")\n",
    "    dataframes_info[df_key] = { 'First_day' : first_day, \n",
    "                                'Last_day'  : last_day, \n",
    "                                'All_days'  : all_days, \n",
    "                                'Num_days'  : num_days }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f218902",
   "metadata": {},
   "source": [
    "### 2. Extart how many samples per each day for each data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "060e3351",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the missing days  \n",
    "missing_days = {}  ## dict to store missing days of each dataframe \n",
    "for df_key, info in dataframes_info.items():\n",
    "    days_list = []   # list to store the missing days  \n",
    "    first_day = info['First_day']\n",
    "    last_day = info['Last_day'] \n",
    "    all_days = info['All_days']\n",
    "    days_between = (last_day - first_day).days  # days between dates \n",
    "    for day in range(days_between+1): \n",
    "        that_day = first_day + pd.to_timedelta(f'{day} day')  \n",
    "        if that_day not in all_days: \n",
    "            days_list.append(that_day)\n",
    "    missing_days[df_key] = days_list;\n",
    "    dataframes_info[df_key]['Missing_days'] = days_list\n",
    "    dataframes_info[df_key]['days_period'] = days_between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7568f9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First_day</th>\n",
       "      <th>Last_day</th>\n",
       "      <th>All_days</th>\n",
       "      <th>Num_days</th>\n",
       "      <th>Missing_days</th>\n",
       "      <th>days_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T1_A26BJ1A</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>{2024-01-29 00:00:00, 2024-03-14 00:00:00, 202...</td>\n",
       "      <td>308</td>\n",
       "      <td>[2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1_A26BJ2A</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>{2024-01-29 00:00:00, 2024-03-14 00:00:00, 202...</td>\n",
       "      <td>308</td>\n",
       "      <td>[2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1_A26BJ2B</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>{2024-01-29 00:00:00, 2024-03-14 00:00:00, 202...</td>\n",
       "      <td>308</td>\n",
       "      <td>[2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1_A26BTAA</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>{2024-01-29 00:00:00, 2024-03-14 00:00:00, 202...</td>\n",
       "      <td>308</td>\n",
       "      <td>[2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1_A26BTAB</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>{2024-01-29 00:00:00, 2024-03-14 00:00:00, 202...</td>\n",
       "      <td>308</td>\n",
       "      <td>[2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            First_day   Last_day  \\\n",
       "T1_A26BJ1A 2023-04-23 2024-03-30   \n",
       "T1_A26BJ2A 2023-04-23 2024-03-30   \n",
       "T1_A26BJ2B 2023-04-23 2024-03-30   \n",
       "T1_A26BTAA 2023-04-23 2024-03-30   \n",
       "T1_A26BTAB 2023-04-23 2024-03-30   \n",
       "\n",
       "                                                     All_days  Num_days  \\\n",
       "T1_A26BJ1A  {2024-01-29 00:00:00, 2024-03-14 00:00:00, 202...       308   \n",
       "T1_A26BJ2A  {2024-01-29 00:00:00, 2024-03-14 00:00:00, 202...       308   \n",
       "T1_A26BJ2B  {2024-01-29 00:00:00, 2024-03-14 00:00:00, 202...       308   \n",
       "T1_A26BTAA  {2024-01-29 00:00:00, 2024-03-14 00:00:00, 202...       308   \n",
       "T1_A26BTAB  {2024-01-29 00:00:00, 2024-03-14 00:00:00, 202...       308   \n",
       "\n",
       "                                                 Missing_days  days_period  \n",
       "T1_A26BJ1A  [2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...          342  \n",
       "T1_A26BJ2A  [2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...          342  \n",
       "T1_A26BJ2B  [2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...          342  \n",
       "T1_A26BTAA  [2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...          342  \n",
       "T1_A26BTAB  [2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...          342  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create a data frame that summarizes the most important infos oabout the data \n",
    "Data_info = pd.DataFrame.from_dict(dataframes_info, orient='index')\n",
    "Data_info.sort_values(by='Num_days', ascending=False, inplace=True)\n",
    "Data_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81e3001",
   "metadata": {},
   "source": [
    "### 3. Work with the top most data according to the number of existing days "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "991c6ce6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First_day</th>\n",
       "      <th>Last_day</th>\n",
       "      <th>All_days</th>\n",
       "      <th>Num_days</th>\n",
       "      <th>Missing_days</th>\n",
       "      <th>days_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T1_A26BJ1A</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>{2024-01-29 00:00:00, 2024-03-14 00:00:00, 202...</td>\n",
       "      <td>308</td>\n",
       "      <td>[2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1_A26BJ2A</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>{2024-01-29 00:00:00, 2024-03-14 00:00:00, 202...</td>\n",
       "      <td>308</td>\n",
       "      <td>[2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1_A26BJ2B</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>{2024-01-29 00:00:00, 2024-03-14 00:00:00, 202...</td>\n",
       "      <td>308</td>\n",
       "      <td>[2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1_A26BTAA</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>{2024-01-29 00:00:00, 2024-03-14 00:00:00, 202...</td>\n",
       "      <td>308</td>\n",
       "      <td>[2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1_A26BTAB</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>{2024-01-29 00:00:00, 2024-03-14 00:00:00, 202...</td>\n",
       "      <td>308</td>\n",
       "      <td>[2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1_A26CBJ1</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>{2024-01-29 00:00:00, 2024-03-14 00:00:00, 202...</td>\n",
       "      <td>307</td>\n",
       "      <td>[2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1_A26CBJ2</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>{2024-01-29 00:00:00, 2024-03-14 00:00:00, 202...</td>\n",
       "      <td>307</td>\n",
       "      <td>[2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1_A26BJ1B</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>{2024-01-29 00:00:00, 2024-03-14 00:00:00, 202...</td>\n",
       "      <td>307</td>\n",
       "      <td>[2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1_BB2</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>{2024-01-29 00:00:00, 2024-03-14 00:00:00, 202...</td>\n",
       "      <td>307</td>\n",
       "      <td>[2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1_BBL1</th>\n",
       "      <td>2023-04-24</td>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>{2023-11-14 00:00:00, 2024-02-07 00:00:00, 202...</td>\n",
       "      <td>306</td>\n",
       "      <td>[2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T3_PTVIB_A</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>2024-03-29</td>\n",
       "      <td>{2023-11-14 00:00:00, 2024-02-07 00:00:00, 202...</td>\n",
       "      <td>306</td>\n",
       "      <td>[2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T3_PTVIB_B</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>2024-03-29</td>\n",
       "      <td>{2023-11-14 00:00:00, 2024-02-07 00:00:00, 202...</td>\n",
       "      <td>306</td>\n",
       "      <td>[2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1_BBH1</th>\n",
       "      <td>2023-04-24</td>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>{2023-11-14 00:00:00, 2024-02-07 00:00:00, 202...</td>\n",
       "      <td>306</td>\n",
       "      <td>[2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1_BB1</th>\n",
       "      <td>2023-04-24</td>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>{2023-11-14 00:00:00, 2024-02-07 00:00:00, 202...</td>\n",
       "      <td>306</td>\n",
       "      <td>[2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            First_day   Last_day  \\\n",
       "T1_A26BJ1A 2023-04-23 2024-03-30   \n",
       "T1_A26BJ2A 2023-04-23 2024-03-30   \n",
       "T1_A26BJ2B 2023-04-23 2024-03-30   \n",
       "T1_A26BTAA 2023-04-23 2024-03-30   \n",
       "T1_A26BTAB 2023-04-23 2024-03-30   \n",
       "T1_A26CBJ1 2023-04-23 2024-03-30   \n",
       "T1_A26CBJ2 2023-04-23 2024-03-30   \n",
       "T1_A26BJ1B 2023-04-23 2024-03-30   \n",
       "T1_BB2     2023-04-23 2024-03-30   \n",
       "T1_BBL1    2023-04-24 2024-03-30   \n",
       "T3_PTVIB_A 2023-04-23 2024-03-29   \n",
       "T3_PTVIB_B 2023-04-23 2024-03-29   \n",
       "T1_BBH1    2023-04-24 2024-03-30   \n",
       "T1_BB1     2023-04-24 2024-03-30   \n",
       "\n",
       "                                                     All_days  Num_days  \\\n",
       "T1_A26BJ1A  {2024-01-29 00:00:00, 2024-03-14 00:00:00, 202...       308   \n",
       "T1_A26BJ2A  {2024-01-29 00:00:00, 2024-03-14 00:00:00, 202...       308   \n",
       "T1_A26BJ2B  {2024-01-29 00:00:00, 2024-03-14 00:00:00, 202...       308   \n",
       "T1_A26BTAA  {2024-01-29 00:00:00, 2024-03-14 00:00:00, 202...       308   \n",
       "T1_A26BTAB  {2024-01-29 00:00:00, 2024-03-14 00:00:00, 202...       308   \n",
       "T1_A26CBJ1  {2024-01-29 00:00:00, 2024-03-14 00:00:00, 202...       307   \n",
       "T1_A26CBJ2  {2024-01-29 00:00:00, 2024-03-14 00:00:00, 202...       307   \n",
       "T1_A26BJ1B  {2024-01-29 00:00:00, 2024-03-14 00:00:00, 202...       307   \n",
       "T1_BB2      {2024-01-29 00:00:00, 2024-03-14 00:00:00, 202...       307   \n",
       "T1_BBL1     {2023-11-14 00:00:00, 2024-02-07 00:00:00, 202...       306   \n",
       "T3_PTVIB_A  {2023-11-14 00:00:00, 2024-02-07 00:00:00, 202...       306   \n",
       "T3_PTVIB_B  {2023-11-14 00:00:00, 2024-02-07 00:00:00, 202...       306   \n",
       "T1_BBH1     {2023-11-14 00:00:00, 2024-02-07 00:00:00, 202...       306   \n",
       "T1_BB1      {2023-11-14 00:00:00, 2024-02-07 00:00:00, 202...       306   \n",
       "\n",
       "                                                 Missing_days  days_period  \n",
       "T1_A26BJ1A  [2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...          342  \n",
       "T1_A26BJ2A  [2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...          342  \n",
       "T1_A26BJ2B  [2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...          342  \n",
       "T1_A26BTAA  [2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...          342  \n",
       "T1_A26BTAB  [2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...          342  \n",
       "T1_A26CBJ1  [2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...          342  \n",
       "T1_A26CBJ2  [2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...          342  \n",
       "T1_A26BJ1B  [2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...          342  \n",
       "T1_BB2      [2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...          342  \n",
       "T1_BBL1     [2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...          341  \n",
       "T3_PTVIB_A  [2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...          341  \n",
       "T3_PTVIB_B  [2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...          341  \n",
       "T1_BBH1     [2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...          341  \n",
       "T1_BB1      [2023-05-14 00:00:00, 2023-05-15 00:00:00, 202...          341  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Top_data = Data_info[Data_info['Num_days'] > 300]\n",
    "Top_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455aa3f1",
   "metadata": {},
   "source": [
    "## D. Adjusting data lengths to be equals \n",
    "     To do this we need to make sure the all the data recording start and ends  at the same dates, as it can be  observed from the 'Top_data' dataframe there is data that starts at 2023-04-23 and other data starts at 2023-04-24, and data that ends at 2024-03-30 and other ends at  2024-03-29, \n",
    "     \n",
    " - We need to slice all datasets at with the commun data recording dates\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65285cb9",
   "metadata": {},
   "source": [
    "### 1. Inspect the dates  to look for the commun dates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "80e95d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inspect the dates  to look for the commun dates \n",
    "first_days = Top_data['First_day']\n",
    "last_days = Top_data['Last_day']\n",
    "commun_dates = [min(first_days), min(last_days)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4317c1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2023-04-23 00:00:00'), Timestamp('2024-03-29 00:00:00')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commun_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "83845b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>T1_A26BJ1A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>0 days 20:11:43.843750</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>0 days 20:23:13.187500</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>0 days 20:30:51.656250</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>0 days 20:42:20.062500</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-23</td>\n",
       "      <td>0 days 20:51:15.343750</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52602</th>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>0 days 02:51:05.656250</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52603</th>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>0 days 02:57:01.718750</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52604</th>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>0 days 03:07:12.875000</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52605</th>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>0 days 03:17:32.125000</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52606</th>\n",
       "      <td>2024-03-30</td>\n",
       "      <td>0 days 03:41:28.906250</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52607 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date                   Time  T1_A26BJ1A\n",
       "0     2023-04-23 0 days 20:11:43.843750        61.0\n",
       "1     2023-04-23 0 days 20:23:13.187500        61.0\n",
       "2     2023-04-23 0 days 20:30:51.656250        61.0\n",
       "3     2023-04-23 0 days 20:42:20.062500        61.0\n",
       "4     2023-04-23 0 days 20:51:15.343750        61.0\n",
       "...          ...                    ...         ...\n",
       "52602 2024-03-30 0 days 02:51:05.656250        38.0\n",
       "52603 2024-03-30 0 days 02:57:01.718750        36.0\n",
       "52604 2024-03-30 0 days 03:07:12.875000        35.0\n",
       "52605 2024-03-30 0 days 03:17:32.125000        34.0\n",
       "52606 2024-03-30 0 days 03:41:28.906250        32.0\n",
       "\n",
       "[52607 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selct the top data frames \n",
    "selcted_data = {} \n",
    "\n",
    "for df_key, df in dataframes.items(): \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e634982",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
